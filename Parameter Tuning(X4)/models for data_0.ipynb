{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa47de33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 161 µs (started: 2022-05-08 16:47:18 +04:00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "397ab526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.9 s (started: 2022-05-08 16:47:18 +04:00)\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../Data/TrainData0.csv\"\n",
    "\n",
    "train_data = pd.read_csv(filepath)\n",
    "\n",
    "filepath = \"../Data/TestData0.csv\"\n",
    "\n",
    "test_data = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02fb2117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 266 ms (started: 2022-05-08 16:47:21 +04:00)\n"
     ]
    }
   ],
   "source": [
    "# Dropping \"Lead Flag\" and \"ZIPCode\" to run LightGBM model on the train and test datasets\n",
    "\n",
    "x_train = train_data.drop(['Lead Flag', 'ZIPCode'], axis=1)\n",
    "y_train = train_data['Lead Flag']\n",
    "\n",
    "x_test = test_data.drop(['Lead Flag', 'ZIPCode'], axis=1)\n",
    "y_test = test_data['Lead Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269213c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 234 µs (started: 2022-05-08 16:47:21 +04:00)\n"
     ]
    }
   ],
   "source": [
    "# In this dictionary the results of LightGBM will be added, then dataframe will be made based on this\n",
    "\n",
    "compare_results_lgbm = {'learning_rate':[], 'max_depth':[], 'score_train':[], 'score_test': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "913b35f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's auc: 0.733022\ttraining's binary_logloss: 0.0497204\n",
      "[40]\ttraining's auc: 0.77015\ttraining's binary_logloss: 0.0476945\n",
      "[60]\ttraining's auc: 0.796037\ttraining's binary_logloss: 0.0461141\n",
      "[80]\ttraining's auc: 0.815317\ttraining's binary_logloss: 0.0448151\n",
      "[100]\ttraining's auc: 0.831934\ttraining's binary_logloss: 0.043588\n",
      "[20]\ttraining's auc: 0.667377\ttraining's binary_logloss: 0.0529871\n",
      "[40]\ttraining's auc: 0.680512\ttraining's binary_logloss: 0.0524929\n",
      "[60]\ttraining's auc: 0.688623\ttraining's binary_logloss: 0.0521995\n",
      "[80]\ttraining's auc: 0.693829\ttraining's binary_logloss: 0.0519939\n",
      "[100]\ttraining's auc: 0.697523\ttraining's binary_logloss: 0.0518394\n",
      "[20]\ttraining's auc: 0.687254\ttraining's binary_logloss: 0.0523098\n",
      "[40]\ttraining's auc: 0.702092\ttraining's binary_logloss: 0.0517355\n",
      "[60]\ttraining's auc: 0.709459\ttraining's binary_logloss: 0.051426\n",
      "[80]\ttraining's auc: 0.715353\ttraining's binary_logloss: 0.0512177\n",
      "[100]\ttraining's auc: 0.718973\ttraining's binary_logloss: 0.0510572\n",
      "[20]\ttraining's auc: 0.701359\ttraining's binary_logloss: 0.0518457\n",
      "[40]\ttraining's auc: 0.717461\ttraining's binary_logloss: 0.0511917\n",
      "[60]\ttraining's auc: 0.726625\ttraining's binary_logloss: 0.0508069\n",
      "[80]\ttraining's auc: 0.732915\ttraining's binary_logloss: 0.0505515\n",
      "[100]\ttraining's auc: 0.737679\ttraining's binary_logloss: 0.0503417\n",
      "[20]\ttraining's auc: 0.71753\ttraining's binary_logloss: 0.0513438\n",
      "[40]\ttraining's auc: 0.737212\ttraining's binary_logloss: 0.0504676\n",
      "[60]\ttraining's auc: 0.748148\ttraining's binary_logloss: 0.0499471\n",
      "[80]\ttraining's auc: 0.756632\ttraining's binary_logloss: 0.04952\n",
      "[100]\ttraining's auc: 0.762902\ttraining's binary_logloss: 0.0491954\n",
      "[20]\ttraining's auc: 0.751634\ttraining's binary_logloss: 0.0487336\n",
      "[40]\ttraining's auc: 0.788477\ttraining's binary_logloss: 0.046964\n",
      "[60]\ttraining's auc: 0.811284\ttraining's binary_logloss: 0.045447\n",
      "[80]\ttraining's auc: 0.830078\ttraining's binary_logloss: 0.0444781\n",
      "[100]\ttraining's auc: 0.842134\ttraining's binary_logloss: 0.0440872\n",
      "[20]\ttraining's auc: 0.678954\ttraining's binary_logloss: 0.0524651\n",
      "[40]\ttraining's auc: 0.693825\ttraining's binary_logloss: 0.051965\n",
      "[60]\ttraining's auc: 0.700426\ttraining's binary_logloss: 0.0516909\n",
      "[80]\ttraining's auc: 0.70556\ttraining's binary_logloss: 0.0515128\n",
      "[100]\ttraining's auc: 0.708053\ttraining's binary_logloss: 0.0513895\n",
      "[20]\ttraining's auc: 0.701058\ttraining's binary_logloss: 0.0517291\n",
      "[40]\ttraining's auc: 0.71511\ttraining's binary_logloss: 0.0512012\n",
      "[60]\ttraining's auc: 0.721724\ttraining's binary_logloss: 0.0509301\n",
      "[80]\ttraining's auc: 0.726287\ttraining's binary_logloss: 0.0507515\n",
      "[100]\ttraining's auc: 0.729615\ttraining's binary_logloss: 0.0506126\n",
      "[20]\ttraining's auc: 0.716612\ttraining's binary_logloss: 0.051176\n",
      "[40]\ttraining's auc: 0.73129\ttraining's binary_logloss: 0.0505843\n",
      "[60]\ttraining's auc: 0.740227\ttraining's binary_logloss: 0.0501807\n",
      "[80]\ttraining's auc: 0.746107\ttraining's binary_logloss: 0.0498944\n",
      "[100]\ttraining's auc: 0.751761\ttraining's binary_logloss: 0.0496059\n",
      "[20]\ttraining's auc: 0.731902\ttraining's binary_logloss: 0.0505474\n",
      "[40]\ttraining's auc: 0.750353\ttraining's binary_logloss: 0.0497081\n",
      "[60]\ttraining's auc: 0.760165\ttraining's binary_logloss: 0.0491736\n",
      "[80]\ttraining's auc: 0.769922\ttraining's binary_logloss: 0.0486967\n",
      "[100]\ttraining's auc: 0.777866\ttraining's binary_logloss: 0.0482352\n",
      "[20]\ttraining's auc: 0.747428\ttraining's binary_logloss: 0.0506624\n",
      "[40]\ttraining's auc: 0.762796\ttraining's binary_logloss: 0.0505448\n",
      "[60]\ttraining's auc: 0.768646\ttraining's binary_logloss: 0.0555317\n",
      "[80]\ttraining's auc: 0.773875\ttraining's binary_logloss: 0.0519342\n",
      "[100]\ttraining's auc: 0.780635\ttraining's binary_logloss: 0.0522666\n",
      "[20]\ttraining's auc: 0.686698\ttraining's binary_logloss: 0.0521435\n",
      "[40]\ttraining's auc: 0.700692\ttraining's binary_logloss: 0.0516691\n",
      "[60]\ttraining's auc: 0.706392\ttraining's binary_logloss: 0.0514289\n",
      "[80]\ttraining's auc: 0.709809\ttraining's binary_logloss: 0.0512877\n",
      "[100]\ttraining's auc: 0.712769\ttraining's binary_logloss: 0.0511887\n",
      "[20]\ttraining's auc: 0.706321\ttraining's binary_logloss: 0.0514433\n",
      "[40]\ttraining's auc: 0.719434\ttraining's binary_logloss: 0.0509769\n",
      "[60]\ttraining's auc: 0.725797\ttraining's binary_logloss: 0.0507377\n",
      "[80]\ttraining's auc: 0.730608\ttraining's binary_logloss: 0.0505586\n",
      "[100]\ttraining's auc: 0.734134\ttraining's binary_logloss: 0.0504036\n",
      "[20]\ttraining's auc: 0.722546\ttraining's binary_logloss: 0.0509052\n",
      "[40]\ttraining's auc: 0.736728\ttraining's binary_logloss: 0.0503019\n",
      "[60]\ttraining's auc: 0.746025\ttraining's binary_logloss: 0.0498942\n",
      "[80]\ttraining's auc: 0.751493\ttraining's binary_logloss: 0.0496043\n",
      "[100]\ttraining's auc: 0.757505\ttraining's binary_logloss: 0.0492895\n",
      "[20]\ttraining's auc: 0.735313\ttraining's binary_logloss: 0.0504574\n",
      "[40]\ttraining's auc: 0.751393\ttraining's binary_logloss: 0.0496704\n",
      "[60]\ttraining's auc: 0.762768\ttraining's binary_logloss: 0.0491404\n",
      "[80]\ttraining's auc: 0.775712\ttraining's binary_logloss: 0.0484745\n",
      "[100]\ttraining's auc: 0.78362\ttraining's binary_logloss: 0.0479072\n",
      "[20]\ttraining's auc: 0.734096\ttraining's binary_logloss: 0.0529824\n",
      "[40]\ttraining's auc: 0.74094\ttraining's binary_logloss: 0.0561083\n",
      "[60]\ttraining's auc: 0.741676\ttraining's binary_logloss: 0.0561405\n",
      "[80]\ttraining's auc: 0.739678\ttraining's binary_logloss: 0.0636057\n",
      "[100]\ttraining's auc: 0.740706\ttraining's binary_logloss: 0.0581839\n",
      "[20]\ttraining's auc: 0.692022\ttraining's binary_logloss: 0.0519245\n",
      "[40]\ttraining's auc: 0.703599\ttraining's binary_logloss: 0.051491\n",
      "[60]\ttraining's auc: 0.709175\ttraining's binary_logloss: 0.0512908\n",
      "[80]\ttraining's auc: 0.712635\ttraining's binary_logloss: 0.0511681\n",
      "[100]\ttraining's auc: 0.714926\ttraining's binary_logloss: 0.0510857\n",
      "[20]\ttraining's auc: 0.709911\ttraining's binary_logloss: 0.0512759\n",
      "[40]\ttraining's auc: 0.720659\ttraining's binary_logloss: 0.0508818\n",
      "[60]\ttraining's auc: 0.727109\ttraining's binary_logloss: 0.0506529\n",
      "[80]\ttraining's auc: 0.732313\ttraining's binary_logloss: 0.0504564\n",
      "[100]\ttraining's auc: 0.736223\ttraining's binary_logloss: 0.0502926\n",
      "[20]\ttraining's auc: 0.7223\ttraining's binary_logloss: 0.0509684\n",
      "[40]\ttraining's auc: 0.734509\ttraining's binary_logloss: 0.0504475\n",
      "[60]\ttraining's auc: 0.741195\ttraining's binary_logloss: 0.0500851\n",
      "[80]\ttraining's auc: 0.748367\ttraining's binary_logloss: 0.0498235\n",
      "[100]\ttraining's auc: 0.753745\ttraining's binary_logloss: 0.0494912\n",
      "[20]\ttraining's auc: 0.73681\ttraining's binary_logloss: 0.050406\n",
      "[40]\ttraining's auc: 0.75137\ttraining's binary_logloss: 0.0499001\n",
      "[60]\ttraining's auc: 0.760869\ttraining's binary_logloss: 0.0492449\n",
      "[80]\ttraining's auc: 0.770582\ttraining's binary_logloss: 0.0486849\n",
      "[100]\ttraining's auc: 0.778471\ttraining's binary_logloss: 0.0480269\n",
      "[20]\ttraining's auc: 0.724472\ttraining's binary_logloss: 0.0585915\n",
      "[40]\ttraining's auc: 0.7263\ttraining's binary_logloss: 0.0593572\n",
      "[60]\ttraining's auc: 0.727839\ttraining's binary_logloss: 0.0622546\n",
      "[80]\ttraining's auc: 0.728621\ttraining's binary_logloss: 0.0657391\n",
      "[100]\ttraining's auc: 0.725999\ttraining's binary_logloss: 0.0635151\n",
      "[20]\ttraining's auc: 0.694843\ttraining's binary_logloss: 0.0517751\n",
      "[40]\ttraining's auc: 0.706586\ttraining's binary_logloss: 0.0513679\n",
      "[60]\ttraining's auc: 0.711704\ttraining's binary_logloss: 0.0511885\n",
      "[80]\ttraining's auc: 0.714994\ttraining's binary_logloss: 0.0510798\n",
      "[100]\ttraining's auc: 0.716815\ttraining's binary_logloss: 0.0510101\n",
      "[20]\ttraining's auc: 0.71078\ttraining's binary_logloss: 0.0512267\n",
      "[40]\ttraining's auc: 0.720227\ttraining's binary_logloss: 0.0509158\n",
      "[60]\ttraining's auc: 0.726273\ttraining's binary_logloss: 0.0506658\n",
      "[80]\ttraining's auc: 0.730662\ttraining's binary_logloss: 0.0504817\n",
      "[100]\ttraining's auc: 0.734596\ttraining's binary_logloss: 0.0503192\n",
      "[20]\ttraining's auc: 0.723191\ttraining's binary_logloss: 0.0508681\n",
      "[40]\ttraining's auc: 0.734716\ttraining's binary_logloss: 0.0504469\n",
      "[60]\ttraining's auc: 0.743104\ttraining's binary_logloss: 0.050008\n",
      "[80]\ttraining's auc: 0.751265\ttraining's binary_logloss: 0.0496529\n",
      "[100]\ttraining's auc: 0.756333\ttraining's binary_logloss: 0.0493728\n",
      "[20]\ttraining's auc: 0.732201\ttraining's binary_logloss: 0.0511037\n",
      "[40]\ttraining's auc: 0.745359\ttraining's binary_logloss: 0.0502378\n",
      "[60]\ttraining's auc: 0.756868\ttraining's binary_logloss: 0.0503142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80]\ttraining's auc: 0.76234\ttraining's binary_logloss: 0.0497375\n",
      "[100]\ttraining's auc: 0.773101\ttraining's binary_logloss: 0.0489234\n",
      "[20]\ttraining's auc: 0.712507\ttraining's binary_logloss: 0.0603574\n",
      "[40]\ttraining's auc: 0.712707\ttraining's binary_logloss: 0.0619432\n",
      "[60]\ttraining's auc: 0.714063\ttraining's binary_logloss: 0.0659184\n",
      "[80]\ttraining's auc: 0.710935\ttraining's binary_logloss: 0.0698029\n",
      "[100]\ttraining's auc: 0.708597\ttraining's binary_logloss: 0.068571\n",
      "[20]\ttraining's auc: 0.69632\ttraining's binary_logloss: 0.0516743\n",
      "[40]\ttraining's auc: 0.70785\ttraining's binary_logloss: 0.0513023\n",
      "[60]\ttraining's auc: 0.712264\ttraining's binary_logloss: 0.051147\n",
      "[80]\ttraining's auc: 0.715193\ttraining's binary_logloss: 0.0510514\n",
      "[100]\ttraining's auc: 0.717321\ttraining's binary_logloss: 0.0509834\n",
      "[20]\ttraining's auc: 0.71065\ttraining's binary_logloss: 0.0512187\n",
      "[40]\ttraining's auc: 0.722055\ttraining's binary_logloss: 0.0508486\n",
      "[60]\ttraining's auc: 0.728192\ttraining's binary_logloss: 0.0506527\n",
      "[80]\ttraining's auc: 0.733367\ttraining's binary_logloss: 0.0504681\n",
      "[100]\ttraining's auc: 0.738417\ttraining's binary_logloss: 0.0502642\n",
      "[20]\ttraining's auc: 0.720985\ttraining's binary_logloss: 0.0510986\n",
      "[40]\ttraining's auc: 0.735192\ttraining's binary_logloss: 0.0508751\n",
      "[60]\ttraining's auc: 0.742711\ttraining's binary_logloss: 0.0502603\n",
      "[80]\ttraining's auc: 0.750922\ttraining's binary_logloss: 0.0499698\n",
      "[100]\ttraining's auc: 0.755584\ttraining's binary_logloss: 0.0498926\n",
      "[20]\ttraining's auc: 0.732611\ttraining's binary_logloss: 0.0511267\n",
      "[40]\ttraining's auc: 0.742469\ttraining's binary_logloss: 0.0507666\n",
      "[60]\ttraining's auc: 0.748829\ttraining's binary_logloss: 0.0505268\n",
      "[80]\ttraining's auc: 0.76196\ttraining's binary_logloss: 0.0507462\n",
      "[100]\ttraining's auc: 0.769665\ttraining's binary_logloss: 0.0501903\n",
      "[20]\ttraining's auc: 0.703437\ttraining's binary_logloss: 0.0612623\n",
      "[40]\ttraining's auc: 0.703582\ttraining's binary_logloss: 0.0641597\n",
      "[60]\ttraining's auc: 0.7025\ttraining's binary_logloss: 0.0685677\n",
      "[80]\ttraining's auc: 0.702314\ttraining's binary_logloss: 0.069978\n",
      "[100]\ttraining's auc: 0.700397\ttraining's binary_logloss: 0.0753961\n",
      "[20]\ttraining's auc: 0.698587\ttraining's binary_logloss: 0.0515883\n",
      "[40]\ttraining's auc: 0.709376\ttraining's binary_logloss: 0.0512522\n",
      "[60]\ttraining's auc: 0.713838\ttraining's binary_logloss: 0.0511039\n",
      "[80]\ttraining's auc: 0.716563\ttraining's binary_logloss: 0.0510113\n",
      "[100]\ttraining's auc: 0.718387\ttraining's binary_logloss: 0.0509422\n",
      "[20]\ttraining's auc: 0.709249\ttraining's binary_logloss: 0.0512622\n",
      "[40]\ttraining's auc: 0.720088\ttraining's binary_logloss: 0.0509218\n",
      "[60]\ttraining's auc: 0.727655\ttraining's binary_logloss: 0.0507348\n",
      "[80]\ttraining's auc: 0.733938\ttraining's binary_logloss: 0.0505067\n",
      "[100]\ttraining's auc: 0.738262\ttraining's binary_logloss: 0.0503271\n",
      "[20]\ttraining's auc: 0.717469\ttraining's binary_logloss: 0.0516187\n",
      "[40]\ttraining's auc: 0.729222\ttraining's binary_logloss: 0.05155\n",
      "[60]\ttraining's auc: 0.73591\ttraining's binary_logloss: 0.051488\n",
      "[80]\ttraining's auc: 0.744768\ttraining's binary_logloss: 0.0507669\n",
      "[100]\ttraining's auc: 0.750063\ttraining's binary_logloss: 0.0506419\n",
      "[20]\ttraining's auc: 0.726374\ttraining's binary_logloss: 0.0513113\n",
      "[40]\ttraining's auc: 0.741549\ttraining's binary_logloss: 0.0509092\n",
      "[60]\ttraining's auc: 0.74741\ttraining's binary_logloss: 0.0516382\n",
      "[80]\ttraining's auc: 0.753815\ttraining's binary_logloss: 0.0514015\n",
      "[100]\ttraining's auc: 0.760388\ttraining's binary_logloss: 0.0511971\n",
      "[20]\ttraining's auc: 0.693908\ttraining's binary_logloss: 0.0674693\n",
      "[40]\ttraining's auc: 0.697275\ttraining's binary_logloss: 0.0689494\n",
      "[60]\ttraining's auc: 0.698385\ttraining's binary_logloss: 0.0738153\n",
      "[80]\ttraining's auc: 0.697614\ttraining's binary_logloss: 0.0780307\n",
      "[100]\ttraining's auc: 0.69574\ttraining's binary_logloss: 0.0779417\n",
      "[20]\ttraining's auc: 0.698133\ttraining's binary_logloss: 0.0515825\n",
      "[40]\ttraining's auc: 0.709033\ttraining's binary_logloss: 0.0512619\n",
      "[60]\ttraining's auc: 0.713604\ttraining's binary_logloss: 0.0511077\n",
      "[80]\ttraining's auc: 0.716638\ttraining's binary_logloss: 0.0510054\n",
      "[100]\ttraining's auc: 0.719\ttraining's binary_logloss: 0.0509277\n",
      "[20]\ttraining's auc: 0.707517\ttraining's binary_logloss: 0.0514869\n",
      "[40]\ttraining's auc: 0.717568\ttraining's binary_logloss: 0.0512546\n",
      "[60]\ttraining's auc: 0.72623\ttraining's binary_logloss: 0.050913\n",
      "[80]\ttraining's auc: 0.731092\ttraining's binary_logloss: 0.0507172\n",
      "[100]\ttraining's auc: 0.734269\ttraining's binary_logloss: 0.0505709\n",
      "[20]\ttraining's auc: 0.723307\ttraining's binary_logloss: 0.0509229\n",
      "[40]\ttraining's auc: 0.732954\ttraining's binary_logloss: 0.0512904\n",
      "[60]\ttraining's auc: 0.738993\ttraining's binary_logloss: 0.0507642\n",
      "[80]\ttraining's auc: 0.742873\ttraining's binary_logloss: 0.0512016\n",
      "[100]\ttraining's auc: 0.747166\ttraining's binary_logloss: 0.0515492\n",
      "[20]\ttraining's auc: 0.721543\ttraining's binary_logloss: 0.0518489\n",
      "[40]\ttraining's auc: 0.735734\ttraining's binary_logloss: 0.0521632\n",
      "[60]\ttraining's auc: 0.740599\ttraining's binary_logloss: 0.0528525\n",
      "[80]\ttraining's auc: 0.744988\ttraining's binary_logloss: 0.0590716\n",
      "[100]\ttraining's auc: 0.747875\ttraining's binary_logloss: 0.059017\n",
      "time: 3min 36s (started: 2022-05-08 16:47:21 +04:00)\n"
     ]
    }
   ],
   "source": [
    "# Running nested for loops to put values in the parameters of LightGBM, run the model, save the train and test scores. \n",
    "\n",
    "results = []\n",
    "for i in np.arange(0.1, 0.9, 0.1):\n",
    "    for j in range(0,5, 1):\n",
    "        \n",
    "        model = lgb.LGBMClassifier(learning_rate=i, max_depth=j, random_state=42)\n",
    "        model.fit(x_train, y_train, eval_set=[(x_train, y_train)], eval_metric='AUC', verbose=20)\n",
    "        \n",
    "        compare_results_lgbm['learning_rate'].append(i)\n",
    "        compare_results_lgbm['max_depth'].append(j)\n",
    "        \n",
    "        Y0_lgbm=model.predict_proba(x_train)[:,1]\n",
    "        Y1_lgbm=model.predict_proba(x_test)[:,1]\n",
    "        \n",
    "        compare_results_lgbm['score_train'].append(roc_auc_score(y_train, Y0_lgbm))\n",
    "        compare_results_lgbm['score_test'].append(roc_auc_score(y_test, Y1_lgbm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b19b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.729615</td>\n",
       "      <td>0.715362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  max_depth  score_train  score_test\n",
       "7            0.2          2     0.729615    0.715362"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.4 ms (started: 2022-05-08 16:50:58 +04:00)\n"
     ]
    }
   ],
   "source": [
    "# Making dataframe from dictionary. Getting the best test score for LightGBM and corresponding parameters.\n",
    "\n",
    "compare_results_lgbm = pd.DataFrame.from_dict(compare_results_lgbm)\n",
    "compare_results_lgbm[compare_results_lgbm['score_test'] == max(compare_results_lgbm['score_test'])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b7f370f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 265 µs (started: 2022-05-08 16:50:58 +04:00)\n"
     ]
    }
   ],
   "source": [
    "# In this dictionary the results of XGBoost will be added, then dataframe will be made based on this\n",
    "\n",
    "compare_results_xgb = {'learning_rate':[], 'max_depth':[], 'score_train':[], 'score_test': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "915a6e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate:  0.1  max_depth:  1\n",
      "[0]\tvalidation_0-auc:0.59582\n",
      "[20]\tvalidation_0-auc:0.59582\n",
      "[40]\tvalidation_0-auc:0.64900\n",
      "[60]\tvalidation_0-auc:0.66925\n",
      "[80]\tvalidation_0-auc:0.68202\n",
      "[99]\tvalidation_0-auc:0.68817\n",
      "learning rate:  0.1  max_depth:  3\n",
      "[0]\tvalidation_0-auc:0.62986\n",
      "[20]\tvalidation_0-auc:0.67053\n",
      "[40]\tvalidation_0-auc:0.68094\n",
      "[60]\tvalidation_0-auc:0.70423\n",
      "[80]\tvalidation_0-auc:0.71919\n",
      "[99]\tvalidation_0-auc:0.72766\n",
      "learning rate:  0.1  max_depth:  5\n",
      "[0]\tvalidation_0-auc:0.63057\n",
      "[20]\tvalidation_0-auc:0.69280\n",
      "[40]\tvalidation_0-auc:0.71563\n",
      "[60]\tvalidation_0-auc:0.74638\n",
      "[80]\tvalidation_0-auc:0.76608\n",
      "[99]\tvalidation_0-auc:0.77651\n",
      "learning rate:  0.1  max_depth:  7\n",
      "[0]\tvalidation_0-auc:0.63092\n",
      "[20]\tvalidation_0-auc:0.71011\n",
      "[40]\tvalidation_0-auc:0.76966\n",
      "[60]\tvalidation_0-auc:0.81519\n",
      "[80]\tvalidation_0-auc:0.84005\n",
      "[99]\tvalidation_0-auc:0.85472\n",
      "learning rate:  0.1  max_depth:  9\n",
      "[0]\tvalidation_0-auc:0.63109\n",
      "[20]\tvalidation_0-auc:0.72974\n",
      "[40]\tvalidation_0-auc:0.83663\n",
      "[60]\tvalidation_0-auc:0.89899\n",
      "[80]\tvalidation_0-auc:0.92077\n",
      "[99]\tvalidation_0-auc:0.93453\n",
      "learning rate:  0.30000000000000004  max_depth:  1\n",
      "[0]\tvalidation_0-auc:0.59582\n",
      "[20]\tvalidation_0-auc:0.66633\n",
      "[40]\tvalidation_0-auc:0.69443\n",
      "[60]\tvalidation_0-auc:0.70342\n",
      "[80]\tvalidation_0-auc:0.70829\n",
      "[99]\tvalidation_0-auc:0.71211\n",
      "learning rate:  0.30000000000000004  max_depth:  3\n",
      "[0]\tvalidation_0-auc:0.62986\n",
      "[20]\tvalidation_0-auc:0.70492\n",
      "[40]\tvalidation_0-auc:0.73140\n",
      "[60]\tvalidation_0-auc:0.74310\n",
      "[80]\tvalidation_0-auc:0.75155\n",
      "[99]\tvalidation_0-auc:0.75829\n",
      "learning rate:  0.30000000000000004  max_depth:  5\n",
      "[0]\tvalidation_0-auc:0.63057\n",
      "[20]\tvalidation_0-auc:0.74403\n",
      "[40]\tvalidation_0-auc:0.78040\n",
      "[60]\tvalidation_0-auc:0.80170\n",
      "[80]\tvalidation_0-auc:0.82088\n",
      "[99]\tvalidation_0-auc:0.83453\n",
      "learning rate:  0.30000000000000004  max_depth:  7\n",
      "[0]\tvalidation_0-auc:0.63092\n",
      "[20]\tvalidation_0-auc:0.80679\n",
      "[40]\tvalidation_0-auc:0.85740\n",
      "[60]\tvalidation_0-auc:0.88147\n",
      "[80]\tvalidation_0-auc:0.90618\n",
      "[99]\tvalidation_0-auc:0.92156\n",
      "learning rate:  0.30000000000000004  max_depth:  9\n",
      "[0]\tvalidation_0-auc:0.63109\n",
      "[20]\tvalidation_0-auc:0.88409\n",
      "[40]\tvalidation_0-auc:0.92736\n",
      "[60]\tvalidation_0-auc:0.95510\n",
      "[80]\tvalidation_0-auc:0.97008\n",
      "[99]\tvalidation_0-auc:0.97941\n",
      "learning rate:  0.5000000000000001  max_depth:  1\n",
      "[0]\tvalidation_0-auc:0.59582\n",
      "[20]\tvalidation_0-auc:0.68491\n",
      "[40]\tvalidation_0-auc:0.70407\n",
      "[60]\tvalidation_0-auc:0.71019\n",
      "[80]\tvalidation_0-auc:0.71357\n",
      "[99]\tvalidation_0-auc:0.71627\n",
      "learning rate:  0.5000000000000001  max_depth:  3\n",
      "[0]\tvalidation_0-auc:0.62986\n",
      "[20]\tvalidation_0-auc:0.72047\n",
      "[40]\tvalidation_0-auc:0.73958\n",
      "[60]\tvalidation_0-auc:0.75278\n",
      "[80]\tvalidation_0-auc:0.76545\n",
      "[99]\tvalidation_0-auc:0.77513\n",
      "learning rate:  0.5000000000000001  max_depth:  5\n",
      "[0]\tvalidation_0-auc:0.63057\n",
      "[20]\tvalidation_0-auc:0.76344\n",
      "[40]\tvalidation_0-auc:0.80147\n",
      "[60]\tvalidation_0-auc:0.82649\n",
      "[80]\tvalidation_0-auc:0.84474\n",
      "[99]\tvalidation_0-auc:0.85857\n",
      "learning rate:  0.5000000000000001  max_depth:  7\n",
      "[0]\tvalidation_0-auc:0.63092\n",
      "[20]\tvalidation_0-auc:0.82623\n",
      "[40]\tvalidation_0-auc:0.88089\n",
      "[60]\tvalidation_0-auc:0.91445\n",
      "[80]\tvalidation_0-auc:0.93219\n",
      "[99]\tvalidation_0-auc:0.95165\n",
      "learning rate:  0.5000000000000001  max_depth:  9\n",
      "[0]\tvalidation_0-auc:0.63109\n",
      "[20]\tvalidation_0-auc:0.90008\n",
      "[40]\tvalidation_0-auc:0.94515\n",
      "[60]\tvalidation_0-auc:0.97581\n",
      "[80]\tvalidation_0-auc:0.98791\n",
      "[99]\tvalidation_0-auc:0.99573\n",
      "learning rate:  0.7000000000000001  max_depth:  1\n",
      "[0]\tvalidation_0-auc:0.59582\n",
      "[20]\tvalidation_0-auc:0.69397\n",
      "[40]\tvalidation_0-auc:0.70752\n",
      "[60]\tvalidation_0-auc:0.71281\n",
      "[80]\tvalidation_0-auc:0.71605\n",
      "[99]\tvalidation_0-auc:0.71813\n",
      "learning rate:  0.7000000000000001  max_depth:  3\n",
      "[0]\tvalidation_0-auc:0.62986\n",
      "[20]\tvalidation_0-auc:0.72640\n",
      "[40]\tvalidation_0-auc:0.74430\n",
      "[60]\tvalidation_0-auc:0.75978\n",
      "[80]\tvalidation_0-auc:0.77229\n",
      "[99]\tvalidation_0-auc:0.78321\n",
      "learning rate:  0.7000000000000001  max_depth:  5\n",
      "[0]\tvalidation_0-auc:0.63057\n",
      "[20]\tvalidation_0-auc:0.77080\n",
      "[40]\tvalidation_0-auc:0.80849\n",
      "[60]\tvalidation_0-auc:0.83700\n",
      "[80]\tvalidation_0-auc:0.85856\n",
      "[99]\tvalidation_0-auc:0.87452\n",
      "learning rate:  0.7000000000000001  max_depth:  7\n",
      "[0]\tvalidation_0-auc:0.63092\n",
      "[20]\tvalidation_0-auc:0.83895\n",
      "[40]\tvalidation_0-auc:0.88164\n",
      "[60]\tvalidation_0-auc:0.91943\n",
      "[80]\tvalidation_0-auc:0.94683\n",
      "[99]\tvalidation_0-auc:0.96587\n",
      "learning rate:  0.7000000000000001  max_depth:  9\n",
      "[0]\tvalidation_0-auc:0.63109\n",
      "[20]\tvalidation_0-auc:0.90249\n",
      "[40]\tvalidation_0-auc:0.95888\n",
      "[60]\tvalidation_0-auc:0.98671\n",
      "[80]\tvalidation_0-auc:0.99736\n",
      "[99]\tvalidation_0-auc:0.99979\n",
      "time: 14min 38s (started: 2022-05-08 16:50:58 +04:00)\n"
     ]
    }
   ],
   "source": [
    "# Running nested for loops to put values in the parameters of XGBoost, run the model, save the train and test scores. \n",
    "\n",
    "results = []\n",
    "for i in np.arange(0.1, 0.9,0.2):\n",
    "    for j in range(1,10, 2):\n",
    "        print('learning rate: ', i, \" max_depth: \", j)\n",
    "        model = XGBClassifier(learning_rate=i, max_depth=j, random_state=42)\n",
    "        model.fit(x_train, y_train, eval_set=[(x_train, y_train)], eval_metric='auc', verbose=20)\n",
    "        compare_results_xgb['learning_rate'].append(i)\n",
    "        compare_results_xgb['max_depth'].append(j)\n",
    "        \n",
    "        \n",
    "        Y0_xgb=model.predict_proba(x_train)[:,1]\n",
    "        Y1_xgb=model.predict_proba(x_test)[:,1]\n",
    "        \n",
    "        compare_results_xgb['score_train'].append(roc_auc_score(y_train, Y0_xgb))\n",
    "        compare_results_xgb['score_test'].append(roc_auc_score(y_test, Y1_xgb)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aee394a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.716266</td>\n",
       "      <td>0.714031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  max_depth  score_train  score_test\n",
       "10            0.5          1     0.716266    0.714031"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.11 ms (started: 2022-05-08 17:05:37 +04:00)\n"
     ]
    }
   ],
   "source": [
    "# Making dataframe from dictionary. Getting the best test score for XGBoost and corresponding parameters.\n",
    "\n",
    "compare_results_xgb = pd.DataFrame.from_dict(compare_results_xgb)\n",
    "compare_results_xgb[compare_results_xgb['score_test'] == max(compare_results_xgb['score_test'])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6ce0a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Train: 0.544602749211782\n",
      "ROC_AUC Test: 0.5438309032958163\n",
      "time: 8.08 s (started: 2022-05-08 17:05:37 +04:00)\n"
     ]
    }
   ],
   "source": [
    "# Running Logistic Regression without regularization \n",
    "\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "logreg.fit(x_train,y_train)\n",
    "\n",
    "Y0_logreg=logreg.predict_proba(x_train)[:,1]\n",
    "Y1_logreg=logreg.predict_proba(x_test)[:,1]\n",
    "\n",
    "print(\"ROC_AUC Train:\", roc_auc_score (y_train, Y0_logreg))\n",
    "print (\"ROC_AUC Test:\", roc_auc_score(y_test, Y1_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fc8051f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC Train: 0.7048604020751943\n",
      "ROC_AUC Test: 0.7063236361220072\n",
      "time: 30.4 s (started: 2022-05-08 17:05:45 +04:00)\n"
     ]
    }
   ],
   "source": [
    "# Running Logistic Regression with regularization. Better results than without regularization\n",
    "\n",
    "logreg=LogisticRegression(C=1,penalty='l1',solver=\"liblinear\", random_state=42)\n",
    "\n",
    "logreg.fit(x_train,y_train)\n",
    "\n",
    "Y0_logreg=logreg.predict_proba(x_train)[:,1]\n",
    "Y1_logreg=logreg.predict_proba(x_test)[:,1]\n",
    "\n",
    "print(\"ROC_AUC Train:\", roc_auc_score (y_train, Y0_logreg))\n",
    "print (\"ROC_AUC Test:\", roc_auc_score(y_test, Y1_logreg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
